# @package model
name:
  DistilBert
load:
  _target_:
    transformers.DistilBertModel.from_pretrained
  pretrained_model_name_or_path:
    distilbert-base-uncased


params:
  loss:
    _target_:
      torch.nn.CrossEntropyLoss
  optimizer:
    _target_:
      torch.optim.Adam
    lr:
      2e-5
  epochs:
    1

trained_path:
  ${paths.main_path}/saved_models/21-47-39.ckpt